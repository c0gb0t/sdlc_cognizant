{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "inc='inc1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the directory: ./data_dir/input_files/inc1\n",
      "./data_dir/input_files/inc1/mail1.txt\n",
      "./data_dir/input_files/inc1/jackhammer.wav\n",
      "./data_dir/input_files/inc1/mail2.txt\n",
      "./data_dir/input_files/inc1/harvard.wav\n"
     ]
    }
   ],
   "source": [
    "# read files form data_dir/input_files directory and create a list of filepaths\n",
    "def create_file_hm(inc):\n",
    "    import os\n",
    "    input_dir=f'./data_dir/input_files/{inc}'\n",
    "    print(f\"Files in the directory: {input_dir}\")\n",
    "    files = os.listdir(input_dir)\n",
    "    # Filtering only the files.\n",
    "    # files = [f for f in files if os.path.isfile(input_dir+'/'+f)]\n",
    "    files = [f for f in files]\n",
    "    files=[f'{input_dir}/{f}' for f in files]\n",
    "    print(*files, sep=\"\\n\")\n",
    "    # fd={}\n",
    "    # for f in files:\n",
    "    #     fd[f]=open(f'{input_dir}/{f}')\n",
    "    # print(fd)\n",
    "    return files\n",
    "files=create_file_hm(inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ./data_dir/input_files/inc1/mail1.txt file----------------\n",
      "reading ./data_dir/input_files/inc1/mail2.txt file----------------\n",
      "this mail contains summary about the incident 34567\n"
     ]
    }
   ],
   "source": [
    "# processing text files\n",
    "def proc_txt_data(files):\n",
    "    txt_files=[f for f in files if '.txt' in f]\n",
    "    txt_data=\"\"\n",
    "    for tf in txt_files:\n",
    "        print(f\"reading {tf} file----------------\")\n",
    "        with open(tf) as f:\n",
    "            txt_data+='\\n'.join(f.readlines())\n",
    "    print(txt_data)\n",
    "    return txt_data\n",
    "txt_data=proc_txt_data(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['stt_key1', 'stt_key2', 'openai-key1', 'openai-key2'])\n"
     ]
    }
   ],
   "source": [
    "# load azure keys\n",
    "import json\n",
    "with open('../keys/azure.json') as json_file:\n",
    "    azure_keys = json.load(json_file)\n",
    "print(azure_keys.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health and zest. A salt pickle tastes fine with ham tacos. Al pastora are my favorite. A zestful food is the hot cross bun.\n",
      "The stale smell of old beer lingers.\n",
      "The stale smell of old beer lingers.\n",
      "The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health and zest. A salt pickle tastes fine with ham tacos. Al pastora are my favorite. A zestful food is the hot cross bun.\n"
     ]
    }
   ],
   "source": [
    "# extract data from azure speech to text api : convert speech to text\n",
    "import sys\n",
    "# %pip install moviepy\n",
    "# from moviepy.editor import *\n",
    "\n",
    "# %pip install azure==4.0.0\n",
    "# % pip install azure-cognitiveservices-speech\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "\n",
    "def proc_video_data(files):\n",
    "    aud_files=[f for f in files if '.mp4' in f or '.wav' in f]\n",
    "    \n",
    "    aud_data=\"\"\n",
    "    for af in aud_files:\n",
    "        speech_key, service_region = azure_keys['stt_key1'], \"eastus\"\n",
    "        speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "        audio_config = speechsdk.audio.AudioConfig(filename=af)\n",
    "        speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "        result = speech_recognizer.recognize_once()\n",
    "        print(result.text)\n",
    "        aud_data+=\"\\n\"+result.text\n",
    "    return aud_data\n",
    "\n",
    "aud_data=proc_video_data(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content to summarize----------------\n",
      " this mail contains summary about the incident 34567\n",
      "The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health and zest. A salt pickle tastes fine with ham tacos. Al pastora are my favorite. A zestful food is the hot cross bun.\n",
      "The stale smell of old beer lingers.\n",
      "The stale smell of old beer lingers.\n",
      "The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health and zest. A salt pickle tastes fine with ham tacos. Al pastora are my favorite. A zestful food is the hot cross bun.\n",
      "\n",
      "\n",
      "summary--------------------------\n",
      " CompletionChoice(finish_reason='length', index=0, logprobs=None, text=' >>>>>>>>>>>>>>   summary    <<<<<<<<<<<<<<<<<< \\nthis mail contains summary about the', content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})\n"
     ]
    }
   ],
   "source": [
    "# create summary from azure open ai api\n",
    "def generate_summary(content):\n",
    "    print(\"content to summarize----------------\\n\",content)\n",
    "    prompt=f\"\"\" \n",
    "    summarize the content from below text data:{content}\n",
    "    \"\"\"\n",
    "    from openai import AzureOpenAI\n",
    "    from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "    deployment = \"Test-GPT\"\n",
    "    endpoint=\"https://genai-warriors-openai-test.openai.azure.com/\"\n",
    "    # token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        # azure_ad_token_provider=token_provider,\n",
    "        api_version=\"2024-02-01\",\n",
    "        api_key=azure_keys['openai-key1']\n",
    "    )\n",
    "    completion = client.completions.create(\n",
    "        model=deployment,\n",
    "        prompt=prompt\n",
    "    )\n",
    "    response=completion\n",
    "    res=response.choices[0]\n",
    "\n",
    "\n",
    "    print(\"\\n\\nsummary--------------------------\\n\",res)\n",
    "    return res\n",
    "   \n",
    "\n",
    "content=txt_data+aud_data\n",
    "summary=generate_summary(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
